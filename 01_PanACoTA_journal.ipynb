{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# **CHAPTER 1. Pangenome analysis**"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Install conda env and activate it**"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "```\n",
    "conda env create -f panacota.yaml\n",
    "```\n",
    "\n",
    "```\n",
    "conda activate panacota\n",
    "```"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## **Part 1: Pangenome building**"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Make a directory to store the data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "! mkdir data/"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Download sequences from `RefSeq` database that match the query `\"Salmonella phage\" AND \"complete genome\"`"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "! esearch -db nucleotide \\\n",
    "    -query '\"Salmonella phage\" AND \"complete genome\" AND srcdb_refseq[PROP] ' \\\n",
    "    | efetch -format fasta > data/salmonella_raw.fasta"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "In the `data/salmonella_raw.fasta` there are many strange sequences like `>NZ_CP019649.1 Salmonella enterica subsp. enterica serovar Typhimurium var. monophasic 4,5,12:i:- strain TW-Stm6 chromosome, complete genome` etc.<br>\n",
    "Eventhough the query to `RefSeq` database was clear there are still a lot of junk in `.fasta` file.<br>\n",
    "Let's remove it!<br>\n",
    "The script below will leave only sequences that has `Salmonella phage` and `complete genome` in their descriptions."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "%run scripts/filter_seqs.py data/salmonella_raw.fasta data/salmonella_251_refseq.fasta"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Now it's time to separate sequences!<br>\n",
    "The script below will take the `.fasta` file with 251 sequences for the input and will store seaparate sequences in the output directory."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Separated fasta files are written to Salmonella_phages directory\n"
     ]
    }
   ],
   "source": [
    "%run scripts/sepfasta.py data/salmonella_251_refseq.fasta Salmonella_phages"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Create the `listFile` file which will have the names of each file<br>\n",
    "It is required to run `PanACoTA`"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "! ls Salmonella_phages/ > data/listFile"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Annotate each genome of `Salmonella phage` that we took in the analysis"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "! PanACoTA annotate -d Salmonella_phages/ -r Annotation -n SaPh -l data/listFile --threads 24"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Build the pangenome and set the parameter of minimum identity to 80%"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "! PanACoTA pangenome -l Annotation/LSTINFO-.lst -n SaPh -d Annotation/Proteins/ -o Pangenome -i 0.8"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Now proceed to `02_Pangenome_vis_journal.R` to investigate the structure of the pangenome!<br>\n",
    "And get back here after then!"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## **Part 2: Getting the most commonly shared genes**"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "So, we must get the genes that are shared in 71 genomes out of 251<br>\n",
    "Let's calculate the percentage!"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "28"
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "round(71 / 251 * 100)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Find genes that has 80% identity in at least 28% of genomes"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "! PanACoTA corepers -p Pangenome/PanGenome-SaPh.All.prt-clust-0.8-mode1.lst -o Coregenome -t 0.28"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Filter `Annotation/LSTINFO-.lst` file and leave there only entries that persist in `Coregenome` output"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Filtered file created: Annotation/filtered_LSTINFO-.lst\n"
     ]
    }
   ],
   "source": [
    "%run scripts/process_LSTINFO.py Coregenome/PersGenome_PanGenome-SaPh.All.prt-clust-0.8-mode1.lst-all_0.28.lst Annotation/LSTINFO-.lst Annotation/filtered_LSTINFO-.lst"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Perform a Multiple Sequences Alignment of that one gene that was identified to have 80% identity in 28% of genomes!"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "! PanACoTA align -c Coregenome/PersGenome_PanGenome-SaPh.All.prt-clust-0.8-mode1.lst-all_0.28.lst -l Annotation/filtered_LSTINFO-.lst -n SaPh -d Annotation/ -o Alignment"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "After that we performed manual BLAST search and decided to design primers for gene family #414"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## **Part 3: Phylogenetics 414**"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Now we must rename sequences in MSA file from `>SaPh.1224.00003.0001b_00001 420 NA | hypothetical protein | NA | NA | NA` to `>NC_006940.2` etc."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "import csv"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "FASTA file has been renamed successfully.\n"
     ]
    }
   ],
   "source": [
    "# Step 1: Load the TSV file into a dictionary\n",
    "tsv_file = 'Annotation/filtered_LSTINFO-.lst'\n",
    "name_mapping = {}\n",
    "\n",
    "with open(tsv_file, 'r') as file:\n",
    "    reader = csv.DictReader(file, delimiter='\\t')\n",
    "    for row in reader:\n",
    "        # Mapping the gembase_name to orig_name without the .fasta extension\n",
    "        gembase_name = row['gembase_name']\n",
    "        orig_name = row['orig_name'].replace('.fasta', '')  # Remove .fasta extension\n",
    "        name_mapping[gembase_name] = orig_name\n",
    "\n",
    "# Step 2: Process the FASTA file and rename headers\n",
    "fasta_file = 'Alignment/Align-SaPh/SaPh-mafft-align.414.aln'\n",
    "output_fasta_file = 'Alignment/Align-SaPh/renamed_SaPh-mafft-align.414.aln'\n",
    "\n",
    "with open(fasta_file, 'r') as infile, open(output_fasta_file, 'w') as outfile:\n",
    "    lines = infile.readlines()\n",
    "    \n",
    "    for line in lines:\n",
    "        if line.startswith('>'):\n",
    "            # Extract the gembase_name from the FASTA header (before the first 3rd dot)\n",
    "            parts = line.split(' ')[0][1:]  # Extract the part before the first space and remove '>'\n",
    "            gembase_name = '.'.join(parts.split('.')[:3])\n",
    "            \n",
    "            # Look up the corresponding NC_XXX.2 name from the dictionary\n",
    "            if gembase_name in name_mapping:\n",
    "                new_header = f\">{name_mapping[gembase_name]}\\n\"\n",
    "                outfile.write(new_header)\n",
    "            else:\n",
    "                # If not found in the mapping, keep the original header\n",
    "                outfile.write(line)\n",
    "        else:\n",
    "            # Write sequence lines as they are\n",
    "            outfile.write(line)\n",
    "\n",
    "print(\"FASTA file has been renamed successfully.\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Launch `Model-Finder` to find the best substitution model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "! mkdir phylogenetics/\n",
    "! mkdir phylogenetics/model-finder/"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "! iqtree2 -m MFP -s Alignment/Align-SaPh/renamed_SaPh-mafft-align.414.aln --prefix phylogenetics/model-finder/tree_MF2 -T AUTO -redo"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Best-fit model according to BIC: Q.plant+G4\n",
      "\n",
      "List of models sorted by BIC scores: \n",
      "\n",
      "Model                  LogL         AIC      w-AIC        AICc     w-AICc         BIC      w-BIC\n",
      "Q.plant+G4        -1033.401    2238.801 -   0.0143    2526.571 +    0.535    2491.166 +    0.355\n"
     ]
    }
   ],
   "source": [
    "! head -42 model-finder/tree_MF2.iqtree | tail -6"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Laucnh `IQ-TREE` to build phylogenetic tree"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "! mkdir phylogenetics/tree/"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "! iqtree2 -s Alignment/Align-SaPh/renamed_SaPh-mafft-align.414.aln -m Q.plant+G4 -pre phylogenetics/tree/tree_ufb -bb 1000 -nt AUTO"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Now parse `Annotation/filtered_LSTINFO-.lst` file to leave only `orig_name` column which will be `accession_numbers.txt` file"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Processing complete. The new file has been created.\n"
     ]
    }
   ],
   "source": [
    "import csv\n",
    "\n",
    "# Input and output file names\n",
    "tsv_file = 'Annotation/filtered_LSTINFO-.lst'\n",
    "output_txt_file = 'data/accession_numbers.txt'\n",
    "\n",
    "# Open the TSV file and process it\n",
    "with open(tsv_file, 'r') as infile, open(output_txt_file, 'w') as outfile:\n",
    "    reader = csv.DictReader(infile, delimiter='\\t')\n",
    "    \n",
    "    # Write the header to the output txt file\n",
    "    #outfile.write(\"orig_name\\n\")\n",
    "    \n",
    "    # Process each row and write the modified orig_name (without \".fasta\")\n",
    "    for row in reader:\n",
    "        orig_name = row['orig_name'].replace('.fasta', '')  # Remove \".fasta\" extension\n",
    "        outfile.write(f\"{orig_name}\\n\")\n",
    "\n",
    "print(\"Processing complete. The new file has been created.\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Install `phyloki`"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "! wget https://raw.githubusercontent.com/iliapopov17/phyloki/refs/heads/v0.525/phyloki.py"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Import `phyloki`"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "from phyloki import *"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Make a directory to store metadata"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "! mkdir metadata/"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Fetch metadata!"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "The request has been fulfilled.\n",
      "File saved to metadata/raw_metadata.tsv\n"
     ]
    }
   ],
   "source": [
    "fetch_metadata('iljapopov17@gmail.com', 'data/accession_numbers.txt', 'metadata/raw_metadata.tsv')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Clean `Year` column to leave only year (withoud the full date)!"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "def clean_year(input_file, output_file):\n",
    "    \"\"\"\n",
    "    Clean the 'Year' column in a metadata .tsv file to extract only the last 4 digits.\n",
    "\n",
    "    Args:\n",
    "        input_file (str): Path to the input .tsv file.\n",
    "        output_file (str): Path to save the cleaned .tsv file.\n",
    "    \"\"\"\n",
    "    # Load the .tsv file into a DataFrame\n",
    "    df = pd.read_csv(input_file, sep=\"\\t\")\n",
    "\n",
    "    # Extract the last 4 digits of the 'Year' column\n",
    "    df['Year'] = df['Year'].apply(lambda x: str(x)[-4:] if pd.notnull(x) else 'ND')\n",
    "\n",
    "    # Save the updated DataFrame to a new .tsv file\n",
    "    df.to_csv(output_file, sep=\"\\t\", index=False)\n",
    "\n",
    "    print(f\"The 'Year' column has been cleaned.\\nFile saved to {output_file}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Run this function!"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "The 'Year' column has been cleaned.\n",
      "File saved to metadata/metadata.tsv\n"
     ]
    }
   ],
   "source": [
    "clean_year('metadata/raw_metadata.tsv', 'metadata/metadata.tsv')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "That's all!<br>\n",
    "Proceed to the `03_phylo_journal.R` to build phylogenetic tree and visualize MSA!<br>\n",
    "After that proceed to the `04_DECIPHER_journal.R` to design degenerative PCR primers for that gene!"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "phoacr",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.13.0"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
